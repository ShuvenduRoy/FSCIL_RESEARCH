base_last	incremental_last	all_last	base	incremental	all	exp_name	dataset	dataroot	result_key	batch_size_base	epochs_base	lr_base	schedule	milestones	step	decay	momentum	ce_loss_factor	moco_dim	moco_k	moco_m	moco_t	moco_loss_factor	num_views	hf_model_checkpoint	encoder	num_mlp	shot	way	session	base_class	incft	test_batch_size	eval_freq	num_workers	seed	num_seeds	gpu	distributed	distributed_launcher	distributed_backend	pet_cls	rank	pet_tuning_start_epoch	encoder_ft_start_layer	adapt_blocks	encoder_ft_start_epoch	encoder_lr_factor	limited_base_class	limited_base_samples	pet_on_teacher	update_base_classifier_with_prototypes	start_training_with_prototypes	add_bias_in_classifier	num_classes	sessions	save_path	size_crops
76.4	61.27	62.78	[92.8, 90.4, 83.83, 81.47, 79.67, 79.1, 78.77, 77.67, 77.17, 76.4]	[nan, 77.07, 72.72, 71.2, 68.66, 65.91, 64.67, 62.42, 62.47, 61.27]	[92.8, 83.73, 76.42, 73.76, 70.86, 68.11, 66.69, 64.33, 64.1, 62.78]	cifar100_baseline	cifar100	./data	_baseline_linear	64	10	0.001	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224	vit-b16	1	10	10	-1	10	False	100	15	8	2	3	0	False	pytorch	nccl	None	5	0	12	[]	0	1	-1	1.0	False	False	True	False	100	10	checkpoint/cifar100_baseline	[224, 224]
75.83	62.1	63.48	[92.47, 89.57, 83.53, 81.03, 79.47, 78.97, 78.33, 77.1, 76.63, 75.83]	[nan, 77.5, 73.87, 71.8, 69.15, 66.32, 65.31, 63.15, 63.3, 62.1]	[92.47, 83.53, 77.09, 74.11, 71.21, 68.43, 67.17, 64.89, 64.78, 63.48]	cifar100_baseline	cifar100	./data	_baseline_linear	64	10	0.0001	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224	vit-b16	1	10	10	-1	10	False	100	15	8	2	3	0	False	pytorch	nccl	None	5	0	12	[]	0	1	-1	1.0	False	False	True	False	100	10	checkpoint/cifar100_baseline	[224, 224]
