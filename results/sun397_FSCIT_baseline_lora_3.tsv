base_last	incremental_last	all_last	all_std_last	base	incremental	all	all_std	exp_name	dataset	dataroot	result_key	batch_size_base	epochs_base	lr_base	schedule	milestones	step	decay	momentum	ce_loss_factor	moco_dim	moco_k	moco_m	moco_t	moco_loss_factor	num_views	hf_model_checkpoint	encoder	num_mlp	shot	fsl_setup	incft	test_batch_size	eval_freq	num_workers	seed	num_seeds	pet_cls	rank	pet_tuning_start_epoch	encoder_ft_start_layer	adapt_blocks	encoder_ft_start_epoch	encoder_lr_factor	limited_base_class	limited_base_samples	pet_on_teacher	update_base_classifier_with_prototypes	start_training_with_prototypes	add_bias_in_classifier	base_class	way	num_classes	sessions	save_path	size_crops
65.95	65.67	65.7	0.0	[87.17, 83.53, 79.87, 77.25, 75.52, 73.8, 73.2, 69.18, 65.95]	[nan, 84.08, 78.63, 74.98, 72.21, 69.91, 67.93, 66.26, 65.67]	[87.17, 83.8, 79.04, 75.54, 72.87, 70.56, 68.68, 66.63, 65.7]	[0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.0, 0.0]	sun397_baseline_lora_fscit	sun397	./data	baseline_lora	64	10	0.001	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224-in21k	vit-b16	1	10	FSCIT	False	100	15	8	2	3	LoRA	5	0	100	[0, 1, 2]	0	1	-1	1.0	False	False	True	False	40	40	397	9	checkpoint/sun397_baseline_lora_fscit	[224, 224]
66.77	65.79	65.89	0.02	[88.57, 84.95, 80.83, 77.95, 76.3, 74.45, 73.9, 70.13, 66.77]	[nan, 84.3, 78.94, 75.17, 72.36, 70.06, 68.06, 66.4, 65.79]	[88.57, 84.62, 79.57, 75.86, 73.14, 70.79, 68.9, 66.87, 65.89]	[0.05, 0.06, 0.02, 0.01, 0.02, 0.02, 0.03, 0.03, 0.02]	sun397_baseline_lora_fscit	sun397	./data	baseline_lora	64	10	0.01	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224-in21k	vit-b16	1	10	FSCIT	False	100	15	8	2	3	LoRA	5	0	100	[0, 1, 2]	0	1	-1	1.0	False	False	True	False	40	40	397	9	checkpoint/sun397_baseline_lora_fscit	[224, 224]
64.77	66.05	65.9	0.04	[89.5, 85.13, 80.02, 77.18, 75.35, 73.62, 72.63, 68.5, 64.77]	[nan, 84.67, 79.63, 75.62, 72.72, 70.35, 68.32, 66.7, 66.05]	[89.5, 84.9, 79.76, 76.01, 73.24, 70.9, 68.94, 66.93, 65.9]	[0.12, 0.11, 0.08, 0.08, 0.06, 0.05, 0.02, 0.02, 0.04]	sun397_baseline_lora_fscit	sun397	./data	baseline_lora	64	10	0.1	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224-in21k	vit-b16	1	10	FSCIT	False	100	15	8	2	3	LoRA	5	0	100	[0, 1, 2]	0	1	-1	1.0	False	False	True	False	40	40	397	9	checkpoint/sun397_baseline_lora_fscit	[224, 224]
