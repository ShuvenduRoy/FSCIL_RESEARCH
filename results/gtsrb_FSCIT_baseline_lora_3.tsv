base_last	incremental_last	all_last	all_std_last	base	incremental	all	all_std	exp_name	dataset	dataroot	result_key	batch_size_base	epochs_base	lr_base	schedule	milestones	step	decay	momentum	ce_loss_factor	moco_dim	moco_k	moco_m	moco_t	moco_loss_factor	num_views	hf_model_checkpoint	encoder	num_mlp	shot	fsl_setup	incft	test_batch_size	eval_freq	num_workers	seed	num_seeds	pet_cls	rank	pet_tuning_start_epoch	encoder_ft_start_layer	adapt_blocks	encoder_ft_start_epoch	encoder_lr_factor	limited_base_class	limited_base_samples	pet_on_teacher	update_base_classifier_with_prototypes	start_training_with_prototypes	add_bias_in_classifier	base_class	way	num_classes	sessions	save_path	size_crops
17.41	16.37	16.6	0.57	[41.59, 25.87, 24.77, 21.68, 21.22, 19.87, 19.23, 18.88, 18.46, 17.41]	[nan, 25.64, 35.55, 29.92, 26.74, 20.84, 18.36, 17.56, 16.88, 16.37]	[41.44, 25.78, 30.68, 26.66, 24.61, 20.42, 18.64, 17.93, 17.32, 16.6]	[0.6, 1.61, 0.96, 0.28, 0.18, 0.23, 0.32, 0.24, 0.44, 0.57]	gtsrb_baseline_lora_fscit	gtsrb	./data	baseline_lora	64	10	0.1	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224-in21k	vit-b16	1	10	FSCIT	False	100	15	8	2	3	LoRA	5	0	100	[0, 1, 2]	0	1	-1	1.0	False	False	True	False	7	4	43	10	checkpoint/gtsrb_baseline_lora_fscit	[224, 224]
14.0	16.33	15.65	0.04	[35.35, 21.3, 19.29, 16.79, 16.54, 15.46, 14.84, 14.54, 14.05, 14.0]	[nan, 22.7, 35.03, 30.24, 26.78, 20.52, 17.72, 17.04, 16.88, 16.33]	[35.23, 21.81, 27.91, 24.94, 22.83, 18.66, 16.76, 16.19, 16.09, 15.65]	[0.14, 0.06, 0.06, 0.05, 0.05, 0.05, 0.05, 0.04, 0.04, 0.04]	gtsrb_baseline_lora_fscit	gtsrb	./data	baseline_lora	64	10	0.001	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224-in21k	vit-b16	1	10	FSCIT	False	100	15	8	2	3	LoRA	5	0	100	[0, 1, 2]	0	1	-1	1.0	False	False	True	False	7	4	43	10	checkpoint/gtsrb_baseline_lora_fscit	[224, 224]
19.89	16.31	17.23	0.22	[40.81, 29.01, 28.14, 23.99, 23.73, 22.42, 21.34, 21.15, 20.64, 19.89]	[nan, 23.37, 33.93, 29.02, 25.68, 20.14, 17.56, 16.87, 16.82, 16.31]	[40.64, 26.89, 31.3, 27.03, 24.89, 20.84, 18.79, 18.14, 17.88, 17.23]	[0.04, 0.35, 0.17, 0.18, 0.18, 0.24, 0.24, 0.22, 0.22, 0.22]	gtsrb_baseline_lora_fscit	gtsrb	./data	baseline_lora	64	10	0.01	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224-in21k	vit-b16	1	10	FSCIT	False	100	15	8	2	3	LoRA	5	0	100	[0, 1, 2]	0	1	-1	1.0	False	False	True	False	7	4	43	10	checkpoint/gtsrb_baseline_lora_fscit	[224, 224]
