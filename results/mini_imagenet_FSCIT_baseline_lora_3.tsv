base_last	incremental_last	all_last	all_std_last	base	incremental	all	all_std	exp_name	dataset	dataroot	result_key	batch_size_base	epochs_base	lr_base	schedule	milestones	step	decay	momentum	ce_loss_factor	moco_dim	moco_k	moco_m	moco_t	moco_loss_factor	num_views	hf_model_checkpoint	encoder	num_mlp	shot	fsl_setup	incft	test_batch_size	eval_freq	num_workers	seed	num_seeds	pet_cls	rank	pet_tuning_start_epoch	encoder_ft_start_layer	adapt_blocks	encoder_ft_start_epoch	encoder_lr_factor	limited_base_class	limited_base_samples	pet_on_teacher	update_base_classifier_with_prototypes	start_training_with_prototypes	add_bias_in_classifier	base_class	way	num_classes	sessions	save_path	size_crops
98.53	94.97	95.32	0.01	[99.4, 99.2, 99.1, 98.9, 98.9, 98.8, 98.8, 98.53, 98.53, 98.53]	[nan, 97.3, 96.55, 96.77, 96.55, 96.66, 96.0, 96.0, 95.08, 94.97]	[99.4, 98.25, 97.4, 97.3, 97.02, 97.02, 96.4, 96.31, 95.46, 95.32]	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01]	mini_imagenet_baseline_lora_fscit	mini_imagenet	data/miniimagenet	baseline_lora	64	10	0.1	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224-in21k	vit-b16	1	10	FSCIT	False	100	15	8	2	3	LoRA	5	0	100	[0, 1, 2]	0	1	-1	1.0	False	False	True	False	10	10	100	10	checkpoint/mini_imagenet_baseline_lora_fscit	[224, 224]
98.4	94.97	95.31	0.0	[99.4, 99.3, 99.2, 99.0, 99.0, 98.9, 98.9, 98.5, 98.4, 98.4]	[nan, 97.3, 96.55, 96.77, 96.55, 96.66, 96.0, 96.0, 95.09, 94.97]	[99.4, 98.3, 97.43, 97.32, 97.04, 97.03, 96.41, 96.31, 95.46, 95.31]	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]	mini_imagenet_baseline_lora_fscit	mini_imagenet	data/miniimagenet	baseline_lora	64	10	0.001	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224-in21k	vit-b16	1	10	FSCIT	False	100	15	8	2	3	LoRA	5	0	100	[0, 1, 2]	0	1	-1	1.0	False	False	True	False	10	10	100	10	checkpoint/mini_imagenet_baseline_lora_fscit	[224, 224]
98.5	94.97	95.32	0.0	[99.47, 99.33, 99.23, 98.97, 98.97, 98.87, 98.87, 98.53, 98.5, 98.5]	[nan, 97.3, 96.55, 96.77, 96.55, 96.66, 96.0, 96.0, 95.08, 94.97]	[99.47, 98.32, 97.44, 97.31, 97.03, 97.03, 96.41, 96.31, 95.46, 95.32]	[0.05, 0.02, 0.02, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0]	mini_imagenet_baseline_lora_fscit	mini_imagenet	data/miniimagenet	baseline_lora	64	10	0.1	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224-in21k	vit-b16	1	10	FSCIT	False	100	15	8	2	3	LoRA	5	0	100	[0, 1, 2]	0	1	-1	1.0	False	False	True	False	10	10	100	10	checkpoint/mini_imagenet_baseline_lora_fscit	[224, 224]
98.4	94.97	95.31	0.0	[99.4, 99.3, 99.2, 99.0, 99.0, 98.9, 98.9, 98.5, 98.4, 98.4]	[nan, 97.3, 96.55, 96.77, 96.55, 96.66, 96.0, 96.0, 95.09, 94.97]	[99.4, 98.3, 97.43, 97.32, 97.04, 97.03, 96.41, 96.31, 95.46, 95.31]	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]	mini_imagenet_baseline_lora_fscit	mini_imagenet	data/miniimagenet	baseline_lora	64	10	0.001	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224-in21k	vit-b16	1	10	FSCIT	False	100	15	8	2	3	LoRA	5	0	100	[0, 1, 2]	0	1	-1	1.0	False	False	True	False	10	10	100	10	checkpoint/mini_imagenet_baseline_lora_fscit	[224, 224]
98.47	94.96	95.31	0.0	[99.4, 99.3, 99.2, 99.0, 99.0, 98.9, 98.9, 98.57, 98.47, 98.47]	[nan, 97.3, 96.55, 96.77, 96.55, 96.66, 96.0, 96.0, 95.08, 94.96]	[99.4, 98.3, 97.43, 97.32, 97.04, 97.03, 96.41, 96.32, 95.45, 95.31]	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0]	mini_imagenet_baseline_lora_fscit	mini_imagenet	data/miniimagenet	baseline_lora	64	10	0.01	Cosine	[60, 70]	40	0.0005	0.9	1.0	128	65536	0.999	0.07	0.0	2	google/vit-base-patch16-224-in21k	vit-b16	1	10	FSCIT	False	100	15	8	2	3	LoRA	5	0	100	[0, 1, 2]	0	1	-1	1.0	False	False	True	False	10	10	100	10	checkpoint/mini_imagenet_baseline_lora_fscit	[224, 224]
